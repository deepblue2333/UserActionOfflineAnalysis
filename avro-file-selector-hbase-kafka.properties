# in this case called 'agent'
agent1.sources = r1
agent1.channels = hbaseC kafkaC
agent1.sinks = hbaseSink kafkaSink

# Define and configure an avro
agent1.sources.r1.type = avro
agent1.sources.r1.channels = KafkaSink hbaseSink
agent1.sources.r1.bind = 0.0.0.0
agent1.sources.r1.port = 1234

# define a selector
agent1.sources.r1.selector.type = replicating

# Configure a file channel
agent1.channels.c1.type = file
agent1.channels.c1.checkpointDir = /opt/data/flume/checkpointDir
agent1.channels.c1.dataDirs = /opt/data/flume/dataDirs

# Define and configure a hbase sink
agent.sinks.hbase-sink.type = org.apache.flume.sink.hbase.HBaseSink
agent.sinks.hbase-sink.table = sogoulogs
agent.sinks.hbase-sink.columnFamily  = familyclom1
agent.sinks.hbase-sink.serializer = org.apache.flume.sink.hbase.RegexHbaseEventSerializer
# 比如我要对nginx日志做分割，然后按列存储HBase，正则匹配分成的列为: ([xxx] [yyy] [zzz] [nnn] ...) 这种格式, 所以用下面的正则:
agent.sinks.hbase-sink.serializer.regex = \\[(.*?)\\]\\ \\[(.*?)\\]\\ \\[(.*?)\\]\\ \\[(.*?)\\]\\ \\[(.*?)\\]\\ \\[(.*?)\\]
agent.sinks.hbase-sink.serializer.colNames = datatime,userid,searchname,retorder,cliorder,cliurl


# Configure a file channel
agent1.channels.c1.type = file
agent1.channels.c1.checkpointDir = /opt/data/flume/checkpointDir2
agent1.channels.c1.dataDirs = /opt/data/flume/dataDirs2

# Define and configure a Kafka sink
agent1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
agent1.sinks.k1.topic = sogoulogs
agent1.sinks.k1.brokerList = cdh02:9092,cdh03:9092,cdh04:9092
agent1.sinks.k1.producer.acks = 1
agent1.sinks.k1.channel = kafkaC