# in this case called 'agent'
agent1.sources = r1
agent1.channels = hbaseC kafkaC
agent1.sinks = hbaseSink kafkaSink

# Define and configure an avro
agent1.sources.r1.type = avro
agent1.sources.r1.channels = hbaseC kafkaC
agent1.sources.r1.bind = 0.0.0.0
agent1.sources.r1.port = 1234

# define a selector
agent1.sources.r1.selector.type = replicating

# Configure a file channel
agent1.channels.hbaseC.type = file
agent1.channels.hbaseC.checkpointDir = /opt/data/flume/checkpointDir
agent1.channels.hbaseC.dataDirs = /opt/data/flume/dataDirs

# Define and configure a hbase sink
agent1.sinks.hbaseSink.type = org.apache.flume.sink.hbase.HBaseSink
agent1.sinks.hbaseSink.table = sogoulogs
agent1.sinks.hbaseSink.columnFamily  = familyclom1
agent1.sinks.hbaseSink.serializer = org.apache.flume.sink.hbase.RegexHbaseEventSerializer
# 比如我要对nginx日志做分割，然后按列存储HBase，正则匹配分成的列为: ([xxx] [yyy] [zzz] [nnn] ...) 这种格式, 所以用下面的正则:
agent1.sinks.hbaseSink.serializer.regex = \\[(.*?)\\]\\ \\[(.*?)\\]\\ \\[(.*?)\\]\\ \\[(.*?)\\]\\ \\[(.*?)\\]\\ \\[(.*?)\\]
agent1.sinks.hbaseSink.serializer.colNames = datatime,userid,searchname,retorder,cliorder,cliurl
agent1.sinks.hbaseSink.channel = hbaseC

# Configure a file channel
agent1.channels.kafkaC.type = file
agent1.channels.kafkaC.checkpointDir = /opt/data/flume/checkpointDir2
agent1.channels.kafkaC.dataDirs = /opt/data/flume/dataDirs2

# Define and configure a Kafka sink
agent1.sinks.kafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
agent1.sinks.kafkaSink.topic = sogoulogs
agent1.sinks.kafkaSink.brokerList = cdh02:9092,cdh03:9092,cdh04:9092
agent1.sinks.kafkaSink.producer.acks = 1
agent1.sinks.kafkaSink.channel = kafkaC